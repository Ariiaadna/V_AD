{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80fc587-9c84-43a5-a7f9-d6e10807bf42",
   "metadata": {},
   "source": [
    "## Загрузка и первичный просмотр данных\n",
    "\n",
    "-Импортирована библиотека pandas.\n",
    "\n",
    "-Загружен файл salary.csv с разделителем ; в датафрейм date_df.\n",
    "\n",
    "-Выполнен вывод датафрейма с помощью display(date_df).\n",
    "\n",
    "-С помощью date_df.info() получена информация о структуре данных: количество строк и столбцов, типы данных, наличие пропусков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5f8af29-2416-4d94-ba12-0d1ae155a23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data SCIENTIST</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>79833.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>HN</td>\n",
       "      <td>HN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>35735.0</td>\n",
       "      <td>HU</td>\n",
       "      <td>HU</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>51321.0</td>\n",
       "      <td>FR</td>\n",
       "      <td>FR</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>126000.0</td>\n",
       "      <td>126000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analytics Manager</td>\n",
       "      <td>150260.0</td>\n",
       "      <td>150260.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     work_year employment_type               job_title      salary  \\\n",
       "0       2020.0              FT          Data SCIENTIST     70000.0   \n",
       "1       2020.0              FT    Product Data Analyst     20000.0   \n",
       "2       2020.0              FT            Data Analyst     72000.0   \n",
       "3       2020.0              FT          Data Scientist  11000000.0   \n",
       "4       2020.0              FT          Data Scientist     45000.0   \n",
       "..         ...             ...                     ...         ...   \n",
       "396     2022.0              FT           Data Engineer    126000.0   \n",
       "397     2022.0              FT            Data Analyst    129000.0   \n",
       "398     2022.0              FT            Data Analyst    150000.0   \n",
       "399     2022.0              FT            Data Analyst     67000.0   \n",
       "400     2022.0              FT  Data Analytics Manager    150260.0   \n",
       "\n",
       "     salary_in_usd employee_residence company_location company_size  \n",
       "0          79833.0                 DE               DE            L  \n",
       "1          20000.0                 HN               HN            S  \n",
       "2          72000.0                 US               US            L  \n",
       "3          35735.0                 HU               HU            L  \n",
       "4          51321.0                 FR               FR            S  \n",
       "..             ...                ...              ...          ...  \n",
       "396       126000.0                 US               US            M  \n",
       "397       129000.0                 US               US            M  \n",
       "398       150000.0                 US               US            M  \n",
       "399        67000.0                 CA               CA            M  \n",
       "400       150260.0                 US               US            M  \n",
       "\n",
       "[401 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 401 entries, 0 to 400\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   work_year           401 non-null    float64\n",
      " 1   employment_type     401 non-null    object \n",
      " 2   job_title           401 non-null    object \n",
      " 3   salary              398 non-null    float64\n",
      " 4   salary_in_usd       401 non-null    float64\n",
      " 5   employee_residence  401 non-null    object \n",
      " 6   company_location    401 non-null    object \n",
      " 7   company_size        401 non-null    object \n",
      "dtypes: float64(3), object(5)\n",
      "memory usage: 25.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "date_df = pd.read_csv('salary.csv', sep = ';')\n",
    "display(date_df)\n",
    "date_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb2f1e3-ae6c-4c58-8cab-639d365989f1",
   "metadata": {},
   "source": [
    "## Общий анализ\n",
    "-date_df.head(20) — просмотрены первые 20 строк датафрейма для оценки содержимого.\n",
    "\n",
    "-date_df.info() — дополнительно проверена структура данных и наличие пустых значений.\n",
    "\n",
    "-date_df.describe() — проведён описательный статистический анализ (среднее, стандартное отклонение, минимум, максимум, квартили).\n",
    "\n",
    "-date_df.columns — выведены названия всех столбцов датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "266f6719-fa94-4840-be58-9c5f44151ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    level_0  index  work_year employment_type                 job_title  \\\n",
      "0         0      0     2020.0              FT            Data Scientist   \n",
      "1         1      1     2020.0              FT      Product Data Analyst   \n",
      "2         2      2     2020.0              FT              Data Analyst   \n",
      "3         3      3     2020.0              FT            Data Scientist   \n",
      "4         4      4     2020.0              FT            Data Scientist   \n",
      "5         5      5     2020.0              FT            Data Scientist   \n",
      "6         6      6     2020.0              FT            Data Scientist   \n",
      "7         7      7     2020.0              FT              Data Analyst   \n",
      "8         8      8     2020.0              FT              Data Analyst   \n",
      "9         9      9     2020.0              FT             Data Engineer   \n",
      "10       10     10     2020.0              FT      Product Data Analyst   \n",
      "11       11     11     2020.0              FT             Data Engineer   \n",
      "12       12     12     2020.0              FT             Data Engineer   \n",
      "13       13     13     2020.0              FT  Machine Learning Manager   \n",
      "14       14     14     2020.0              FT            Data Scientist   \n",
      "15       15     15     2020.0              FT              Data Analyst   \n",
      "16       16     16     2020.0              FT             Data Engineer   \n",
      "17       17     17     2020.0              FT              Data Analyst   \n",
      "18       18     18     2020.0              FT            Data Scientist   \n",
      "19       19     19     2020.0              FT             Data Engineer   \n",
      "\n",
      "        salary  salary_in_usd employee_residence company_location company_size  \n",
      "0      70000.0        79833.0                 DE               DE            L  \n",
      "1      20000.0        20000.0                 HN               HN            S  \n",
      "2      72000.0        72000.0                 US               US            L  \n",
      "3   11000000.0        35735.0                 HU               HU            L  \n",
      "4      45000.0        51321.0                 FR               FR            S  \n",
      "5    3000000.0        40481.0                 IN               IN            L  \n",
      "6      35000.0        39916.0                 FR               FR            M  \n",
      "7      85000.0        85000.0                 US               US            L  \n",
      "8       8000.0         8000.0                 PK               PK            L  \n",
      "9    4450000.0        41689.0                 JP               JP            S  \n",
      "10    450000.0         6072.0                 IN               IN            L  \n",
      "11     42000.0        47899.0                 GR               GR            L  \n",
      "12    720000.0        33511.0                 MX               MX            S  \n",
      "13    157000.0       117104.0                 CA               CA            L  \n",
      "14     60000.0        68428.0                 GR               US            L  \n",
      "15     41000.0        46759.0                 FR               FR            L  \n",
      "16     65000.0        74130.0                 AT               AT            L  \n",
      "17     10000.0        10000.0                 NG               NG            S  \n",
      "18     45760.0        45760.0                 PH               US            S  \n",
      "19    106000.0       106000.0                 US               US            L  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 346 entries, 0 to 345\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   level_0             346 non-null    int64  \n",
      " 1   index               346 non-null    int64  \n",
      " 2   work_year           346 non-null    float64\n",
      " 3   employment_type     346 non-null    object \n",
      " 4   job_title           346 non-null    object \n",
      " 5   salary              344 non-null    float64\n",
      " 6   salary_in_usd       346 non-null    float64\n",
      " 7   employee_residence  346 non-null    object \n",
      " 8   company_location    346 non-null    object \n",
      " 9   company_size        346 non-null    object \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 27.2+ KB\n",
      "None\n",
      "         level_0       index    work_year        salary  salary_in_usd\n",
      "count  346.00000  346.000000   346.000000  3.440000e+02     346.000000\n",
      "mean   172.50000  184.369942  2021.459538  3.142805e+05  102100.462428\n",
      "std    100.02583  113.340000     0.701827  1.802857e+06   59239.075857\n",
      "min      0.00000    0.000000  2020.000000  4.000000e+03    2859.000000\n",
      "25%     86.25000   86.250000  2021.000000  6.342500e+04   60000.000000\n",
      "50%    172.50000  175.500000  2022.000000  1.050000e+05   99025.000000\n",
      "75%    258.75000  282.750000  2022.000000  1.500000e+05  135000.000000\n",
      "max    345.00000  398.000000  2022.000000  3.040000e+07  412000.000000\n",
      "Index(['level_0', 'index', 'work_year', 'employment_type', 'job_title',\n",
      "       'salary', 'salary_in_usd', 'employee_residence', 'company_location',\n",
      "       'company_size'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(date_df.head(20))\n",
    "print(date_df.info())\n",
    "print(date_df.describe())\n",
    "print(date_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012a744-e8e1-4e4d-86c2-ec63369377d8",
   "metadata": {},
   "source": [
    "## вывод\n",
    "#### (дада, я дурдачок и делаю это после всех заданий, извените пожалуйста, обещаю в след раз читать методу внимательно и по порядку Простите `(*>﹏<*)′)\n",
    "С помощью метода `head(20)` были просмотрены первые строки датасета, чтобы понять структуру таблицы.  \n",
    "\n",
    "Датасет содержит сведения о зарплатах специалистов в сфере анализа данных. Поля включают: год (`work_year`), тип занятости (`employment_type`), должность (`job_title`), зарплату в валюте компании (`salary`) и в долларах (`salary_in_usd`), страну проживания сотрудника (`employee_residence`), страну офиса компании (`company_location`) и размер компании (`company_size`). \n",
    "Метод `info()` показал, что в датасете 346 строк и 10 столбцов. Обнаружены 2 пропущенных значения в поле `salary`. \n",
    "Типы данных — числовые (`int64`, `float64`) и категориальные (`object`).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9c332-16f5-4947-8215-231780cd3a22",
   "metadata": {},
   "source": [
    "## Первое задание \n",
    "### Групировка и подсчёт количества в стобце локация\n",
    "#### Описание\n",
    "Группировка – \"`employment_type`\" и количество каждой локации \"`company_location`\". \n",
    "Задание означает что нужно «сгрупировать» данные по столбцу \"`employment_type`\" и подсчитать количество каждой локации. Группировка в pandas осуществляется с помощью `groupby()`:\n",
    "метод принимает в качестве аргумента название столбца, по которому нужно группировать (например, год, пол, категория). В данном случае `employment_type`.\n",
    "метод возвращает объект типа DataFrameGroupBy , то есть сгруппированные данные, к которым можно применять различные методы (`count, sum, min, max, mean, last`). \n",
    "В методических указаниях есть пример подходящий для данного задания: \n",
    "`df.groupby('column1')['n'].count() # группировка по column1 и подсчет количества элементов в конкретном столбце n`\n",
    "\tСоответственно выполняем следующий код на наших данных. \n",
    "*Наивно применяю функцию из методы в надежде что это сработает)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5391e2-b962-4d5a-8858-5d8272e8158e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employment_type\n",
       "FL      2\n",
       "FT    394\n",
       "PT      5\n",
       "Name: company_location, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df.groupby('employment_type')['company_location'].count() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7bf764-dd3f-4a09-84fd-681d4e3dc9b3",
   "metadata": {},
   "source": [
    "### Вторая попытка\n",
    "Конечно, этого было недостаточно, т.к. результат не похож на фрагмент, представленный в задание. \n",
    "Далее была вторая попытка применить метод `value_counts()`, который анализирует столбец, показывает каждое уникальное значение, прим этом подсчитывая частоту его встречаемости в списке, результат это пары: значение и частота, отсортированные по убыванию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "385ca4ec-fce3-4ccb-ab4f-3f8fe6dca78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employment_type  company_location\n",
      "FL               US                    2\n",
      "FT               US                  252\n",
      "                 GB                   37\n",
      "                 CA                   19\n",
      "                 IN                   13\n",
      "                 DE                   12\n",
      "                 FR                   11\n",
      "                 ES                    9\n",
      "                 GR                    9\n",
      "                 AT                    3\n",
      "                 MX                    3\n",
      "                 TR                    3\n",
      "                 NG                    2\n",
      "                 PK                    2\n",
      "                 PL                    2\n",
      "                 AU                    1\n",
      "                 BR                    1\n",
      "                 CH                    1\n",
      "                 CL                    1\n",
      "                 HN                    1\n",
      "                 HU                    1\n",
      "                 IL                    1\n",
      "                 IQ                    1\n",
      "                 IR                    1\n",
      "                 JP                    1\n",
      "                 LU                    1\n",
      "                 MT                    1\n",
      "                 MY                    1\n",
      "                 NL                    1\n",
      "                 RU                    1\n",
      "                 UA                    1\n",
      "                 VN                    1\n",
      "PT               DE                    1\n",
      "                 DZ                    1\n",
      "                 ES                    1\n",
      "                 IT                    1\n",
      "                 NL                    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(date_df.groupby('employment_type')['company_location'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa461793-0e44-4a06-8380-62e7d19715f2",
   "metadata": {},
   "source": [
    "## Вывод по первому заданию\n",
    "В результате группировки по типу занятости и локации компании видно, что подавляющее большинство работников представлено в категории Full-time (FT). Наибольшее количество записей относится к США (252 случая), что указывает на доминирование американского рынка в наборе данных. Freelance (FL) встречается крайне редко (2 случая в США), а Part-time (PT) также имеет минимальное количество записей, распределённых по разным странам. Это позволяет сделать вывод, что набор данных в основном описывает сотрудников, работающих на полной занятости в крупных компаниях, преимущественно с головными офисами в США."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3888b51e-172c-48d8-b029-edaf78883038",
   "metadata": {},
   "source": [
    "## Второе задание\n",
    "Попробуем аналогичную логику первого задания, но переименовать столбец и добавить стортировку\n",
    "Использован метод groupby для группировки данных по году работы ('work_year') и размеру компании ('company_size').\n",
    "\n",
    "С помощью 'value_counts()' подсчитано количество записей для каждой комбинации.\n",
    "\n",
    "Результат преобразован в датафрейм с помощью '.reset_index()'.\n",
    "\n",
    "Выполнена сортировка по столбцу count в порядке убывания ('ascending = False').\n",
    "\n",
    "Итоговый датафрейм 'd_q2' выведен на экран ('print(d_q2)'), что позволяет определить наиболее часто встречающиеся комбинации года работы и размера компании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa71623-1ce3-43ac-9076-deae26e8fdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   work_year company_size  count\n",
      "7     2022.0            M    222\n",
      "4     2021.0            L     57\n",
      "5     2021.0            M     30\n",
      "8     2022.0            L     27\n",
      "0     2020.0            L     21\n",
      "6     2021.0            S     18\n",
      "1     2020.0            S     15\n",
      "2     2020.0            M      5\n",
      "9     2022.0            S      5\n",
      "3     2020.0        Large      1\n"
     ]
    }
   ],
   "source": [
    "d_q2 = date_df.groupby('work_year')['company_size'].value_counts().reset_index()\n",
    "d_q2 = d_q2.sort_values(by='count',ascending = False)\n",
    "print(d_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1543240e-6a95-4c42-97c9-3afa17b5340b",
   "metadata": {},
   "source": [
    "#### Пу пу пу\n",
    "Тут стало понятно что я немного(много)дурдочка - данные нужно было предобработать... \n",
    "Предобработка данных:\n",
    "- С помощью функции `date_df.duplicated().sum()` было обнаружено 55 явных дубликатов, которые были удалены с помощью `date_df = date_df.drop_duplicates().reset_index(drop=True)`\n",
    "- Были проанализированные уникальные значения во всех столбцах кроме `salary` и s`alary_in_usd` и переименнованы неверно названные. \n",
    "- В столбце salary обнаружены 3 пропущенных значения, тогда как в 'salary_in_usd' отсутствуют пропуски. Так как именно 'salary_in_usd' используется для анализа, отсутствующие значения в 'salary' не влияют на результаты и были оставлены без заполнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78ed6916-e5de-4295-9f13-26c4b2174288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[2020. 2021. 2022.]\n",
      "['L' 'S' 'M' 'Large']\n",
      "['FT' 'PT' 'FL']\n",
      "['Data SCIENTIST' 'Product Data Analyst' 'Data Analyst' 'Data Scientist'\n",
      " 'Data Engineer' 'Machine Learning Manager' 'Data Analytics Engineer'\n",
      " 'Data Science Engineer' 'Machine Learning Developer'\n",
      " 'Data Analytics Manager' 'Head of Data Science'\n",
      " 'Head of Machine Learning' 'NLP Engineer' 'Data Analytics Lead'\n",
      " 'DataScientist' 'Data AnalyticsManager']\n",
      "['DE' 'HN' 'US' 'HU' 'FR' 'IN' 'PK' 'JP' 'GR' 'MX' 'CA' 'AT' 'NG' 'PH'\n",
      " 'GB' 'ES' 'IT' 'PL' 'BG' 'NL' 'IQ' 'UA' 'SG' 'RU' 'MT' 'CL' 'RO' 'IR'\n",
      " 'VN' 'BR' 'HK' 'TR' 'RS' 'AR' 'DZ' 'AU' 'CH']\n",
      "['DE' 'HN' 'US' 'HU' 'FR' 'IN' 'PK' 'JP' 'GR' 'MX' 'CA' 'AT' 'NG' 'GB'\n",
      " 'ES' 'IT' 'LU' 'PL' 'NL' 'IQ' 'UA' 'IL' 'RU' 'MT' 'CL' 'IR' 'BR' 'VN'\n",
      " 'TR' 'DZ' 'MY' 'AU' 'CH']\n"
     ]
    }
   ],
   "source": [
    "print(date_df.duplicated().sum()) #выводим количество явных дубликатов\n",
    "date_df = date_df.drop_duplicates().reset_index(drop=True) #удаляем дубликаты\n",
    "print(date_df['work_year'].unique()) # Поиск уникальных значений в указаном столбце\n",
    "print(date_df['company_size'].unique()) # Поиск уникальных значений в указаном столбце\n",
    "print(date_df['employment_type'].unique()) # Поиск уникальных значений в указаном столбце\n",
    "print(date_df['job_title'].unique()) # Поиск уникальных значений в указаном столбце\n",
    "print(date_df['employee_residence'].unique()) # Поиск уникальных значений в указаном столбце\n",
    "print(date_df['company_location'].unique()) # Поиск уникальных значений в указаном столбце\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8991fa52-93d1-4770-b08a-f09f8733f173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L' 'S' 'M']\n",
      "['Data Scientist' 'Product Data Analyst' 'Data Analyst' 'Data Engineer'\n",
      " 'Machine Learning Manager' 'Data Analytics Engineer'\n",
      " 'Data Science Engineer' 'Machine Learning Developer'\n",
      " 'Data Analytics Manager' 'Head of Data Science'\n",
      " 'Head of Machine Learning' 'NLP Engineer' 'Data Analytics Lead']\n"
     ]
    }
   ],
   "source": [
    "date_df['company_size'] = date_df['company_size'].replace('Large', 'L')\n",
    "\n",
    "duplicates_job_title = ['Data SCIENTIST', 'DataScientist'] # список неправильных названий\n",
    "name_job_title = 'Data Scientist'# правильное название\n",
    "date_df['job_title'] = date_df['job_title'].replace(duplicates_job_title, name_job_title) \n",
    "date_df['job_title'] = date_df['job_title'].replace('Data AnalyticsManager', 'Data Analytics Manager')\n",
    "print(date_df['company_size'].unique()) # Поиск уникальных значений в указаном столбце\n",
    "print(date_df['job_title'].unique()) # Поиск уникальных значений в указаном столбце\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07fe123f-b62e-4091-84a9-396771a76029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   work_year company_size  count\n",
      "6     2022.0            M    174\n",
      "3     2021.0            L     55\n",
      "4     2021.0            M     30\n",
      "7     2022.0            L     23\n",
      "0     2020.0            L     22\n",
      "5     2021.0            S     18\n",
      "1     2020.0            S     15\n",
      "2     2020.0            M      5\n",
      "8     2022.0            S      4\n"
     ]
    }
   ],
   "source": [
    "d_q2 = date_df.groupby('work_year')['company_size'].value_counts().reset_index()\n",
    "d_q2 = d_q2.sort_values(by='count',ascending = False)\n",
    "print(d_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7858c55b-117e-42a8-9814-ddabb9a09db7",
   "metadata": {},
   "source": [
    "## Вывод по второму заданию\n",
    "По результатам группировки можно сделать вывод, что в датасете преобладают компании среднего размера (M), особенно в 2022 году (174 записи). Компании большого размера (L) стабильно занимают значимую долю, а малые компании (S) встречаются значительно реже, причём их количество снижается от 2020 к 2022 году. Таким образом, выборка данных в основном отражает сотрудников средних компаний 2022 и крупных компаний 2021, при этом малые компании представлены минимально."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a10cf-d07b-44ca-acfc-12511ecd6528",
   "metadata": {},
   "source": [
    "# Задание 3\n",
    "Сводная таблица по запрплатам и должностям\n",
    "С помощью метода `pivot_table()` была построена сводная таблица, где в строках указаны должности, а в значениях — средняя зарплата. С помощью `reset_index()` индекс был преобразован в обычный столбец, чтобы таблица имела привычный вид. \n",
    "Методом `round(2)` значения были округлены до двух знаков после запятой. \n",
    "Столбец с зарплатами был переименован с 'salary_in_usd' на более понятное название \"зарплата\" с помощью функции 'rename()'.\n",
    "Для отображения должностей от самой высокой к самой низкой средней зарплате применена сортировка 'sort_values(by=\"зарплата\", ascending=False)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b12ee109-e8c1-4b5d-9368-3920d820aa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>зарплата</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analytics Lead</td>\n",
       "      <td>405000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Head of Data Science</td>\n",
       "      <td>146718.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analytics Manager</td>\n",
       "      <td>127134.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Machine Learning Manager</td>\n",
       "      <td>117104.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>109295.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>102623.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Machine Learning Developer</td>\n",
       "      <td>89395.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>88597.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Head of Machine Learning</td>\n",
       "      <td>79039.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>75803.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analytics Engineer</td>\n",
       "      <td>64799.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NLP Engineer</td>\n",
       "      <td>37236.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>13036.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     job_title   зарплата\n",
       "2          Data Analytics Lead  405000.00\n",
       "7         Head of Data Science  146718.75\n",
       "3       Data Analytics Manager  127134.29\n",
       "10    Machine Learning Manager  117104.00\n",
       "4                Data Engineer  109295.46\n",
       "6               Data Scientist  102623.46\n",
       "9   Machine Learning Developer   89395.50\n",
       "0                 Data Analyst   88597.23\n",
       "8     Head of Machine Learning   79039.00\n",
       "5        Data Science Engineer   75803.33\n",
       "1      Data Analytics Engineer   64799.25\n",
       "11                NLP Engineer   37236.00\n",
       "12        Product Data Analyst   13036.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Сводная таблица: средняя зарплата по должностям\n",
    "pivot = date_df.pivot_table(index=['job_title'], values='salary_in_usd',aggfunc='mean')\n",
    "pivot = pivot.reset_index()\n",
    "pivot[\"salary_in_usd\"] = pivot[\"salary_in_usd\"].round(2)\n",
    "pivot = pivot.rename(columns={\"salary_in_usd\": \"зарплата\"})\n",
    "pivot = pivot.sort_values(by=\"зарплата\", ascending=False)\n",
    "display(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ab0f3-ddee-468c-9195-c9b76570a16b",
   "metadata": {},
   "source": [
    "## Вывод третьему заданию\n",
    "По результатам анализа видно, что наибольшие средние зарплаты характерны для руководящих должностей. Средний уровень зарплат наблюдается у специальностей, которые входят в число наиболее востребованных специалистов. Наименьшие значения характерны для узкопрофильных позиций, что может быть связано как с меньшим количеством данных по ним, так и с особенностями рынка. В целом, таблица отражает закономерность: чем выше управленческая роль, тем выше средняя зарплата."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b1c7b5-1dc0-4969-9d32-1451c5d8d34e",
   "metadata": {},
   "source": [
    "## Задание 4\n",
    "Используя уже использованные ранее методы строим таблицу\n",
    "`pivot_table()` – построение сводной таблицы: строки = `work_year`, столбцы = `employment_type`, значения = медианная зарплата (`salary_in_usd`). `aggfunc=\"median\"` – расчёт медианного значения вместо среднего.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67142418-e425-4560-81ae-3c2ceb78777c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>employment_type</th>\n",
       "      <th>FL</th>\n",
       "      <th>FT</th>\n",
       "      <th>PT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022.0</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>115967.0</td>\n",
       "      <td>77478.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021.0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>79598.5</td>\n",
       "      <td>40047.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>68428.0</td>\n",
       "      <td>21669.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "employment_type        FL        FT       PT\n",
       "work_year                                   \n",
       "2022.0           100000.0  115967.0  77478.5\n",
       "2021.0            20000.0   79598.5  40047.5\n",
       "2020.0                NaN   68428.0  21669.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pivot2 = date_df.pivot_table(values='salary_in_usd', index='work_year', columns='employment_type', aggfunc='median')\n",
    "pivot2 = pivot2.sort_values(by='work_year',ascending = False)\n",
    "display(pivot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a871beef-f07e-4ead-8feb-91e52ee09b82",
   "metadata": {},
   "source": [
    "## Вывод по четвертому заданию\n",
    "Медианные зарплаты растут по всем типам занятости с 2020 по 2022 гг. Наибольшие значения наблюдаются у FT, достигнув 116 тыс.  в 2022 году. FL представлен только с 2021 года, при этом медиана резко выросла до 100 тыс. в 2022 году. PT имеет значительно более низкие зарплаты, но также демонстрирует рост."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c25a6e-fb54-478c-accb-6dc250a34002",
   "metadata": {},
   "source": [
    "# ОБЩИЙ ВЫВОД\n",
    "Анализировался набор данных **salary.csv**, содержащий сведения о зарплатах специалистов в области данных за **2020–2022 годы**: тип занятости, должность, страна проживания, страна офиса, размер компании и доход в долларах США.\n",
    "\n",
    "### Предобработка данных\n",
    "\n",
    "* Чтение файла через `pd.read_csv()`.\n",
    "* Первичный обзор с помощью `head()`, `info()`, `describe()`.\n",
    "* Удаление **55 явных дубликатов** методом `drop_duplicates()`.\n",
    "* Выявление и устранение некорректных значений категориальных признаков.\n",
    "* Обнаружено **3 пропуска в salary** при отсутствии их в `salary_in_usd`; решение — оставить без заполнения, так как для анализа использовался именно `salary_in_usd`.\n",
    "* Приведение типа `work_year` к **int**.\n",
    "\n",
    "### Основные результаты анализа\n",
    "\n",
    "* **Группировка по типу занятости и локации (задание 1):** подавляющее большинство сотрудников работают **Full-time**, основная часть данных относится к **США**; **Part-time** и **Freelance** встречаются редко.\n",
    "* **Группировка по году и размеру компании:** наибольшая часть данных приходится на **2022 год**; преобладают компании среднего размера (**M**), доля малых компаний (**S**) снижается.\n",
    "* **Сводная таблица по должности и зарплате в долларах:** руководящие должности имеют наибольшие средние зарплаты, тогда как узкопрофильные роли получают заметно меньше.\n",
    "* **Сводная таблица по году и типу занятости:** медианные зарплаты стабильно растут с 2020 по 2022 гг.; **FT** выше, чем **PT**, а в 2022 г. **FL** приблизился по медиане к FT.\n",
    "* **Средняя зарплата** по выборке составила ≈ **105 895 USD**, медианная — более **100 000 USD**; диапазон колеблется от **2 859 до 412 000 USD**.\n",
    "\n",
    "### Итог\n",
    "\n",
    "Данные отражают рынок труда специалистов в области данных за **2020–2022 гг.**:\n",
    "\n",
    "* доминируют контракты **полной занятости**;\n",
    "* основная часть компаний находится в **США**;\n",
    "* преобладают **средние и крупные работодатели**;\n",
    "* уровень зарплат демонстрирует рост по всем категориям занятости.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b13f6-0589-4941-9609-368616b83a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
